# -*- coding: utf-8 -*-
"""Labkiemtraso1_207CT27605_Dinh Thach Bao.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12PvyzneNnhofekYj6njWjiDhuJX8IPvA

# Đề kiểm tra lập trình nhập môn phân tích dữ liệu và học sâu

### Sinh viên không được phép sử dụng internet
### Sinh viên sau khi làm bài xong xuất ra file PDF đồng thời nộp lên Fit-lab và push lên git-hub
### Sinh viên làm bắt đầu làm bài từ 15h40 - 18h00
"""

# Họ và Tên: Đinh Thạch Bảo
# MSSV: 207CT27605

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
import numpy as np
from sklearn.datasets import load_iris
import matplotlib.pyplot as plt

#Bước 1: Load data
def load_dataset():
    X, y = load_iris(return_X_y=True)
    X = X[y!=2]
    y = y[y!=2]
    return X,y
#Điền ở đây
X, y = load_dataset()
print(X.shape, y.shape)

"""Kết quả: (100, 4) (100,)"""

#Trực quan hóa dữ liệu data
#Điền code ở đây
plt.scatter(X[:,0], X[:,1],c=y)

"""Kết quả

![image.png](attachment:image.png)
"""

# Bước 2: Định nghĩa mô hình hồi quy logistic bằng PyTorch
class LogisticRegressTorch(nn.Module):
    def __init__(self, n_features):
        super(LogisticRegressTorch, self).__init__()
        self.linear = nn.Linear(n_features, 1) # tạo một lớp tuyến tính (nn.Linear) với n_features đầu vào và 1 đầu ra
        n_features = X.shape[1]



    def forward(self, x):
        return torch.sigmoid(self.linear(x))

model = LogisticRegressTorch(n_features)

# Bước 3: Định nghĩa lớp dữ liệu
class IrisTorch(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)

    def __len__(self):
        return len(self.X)           #trả về số lượng mẫu trong tập dữ liệu (số lượng hàng trong self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]           #trả về một cặp đặc trưng và nhãn tương ứng với chỉ số idx

# Tạo dữ liệu
dataset = IrisTorch(X, y)
dataloader = DataLoader(dataset, batch_size=4, shuffle=True)

# Kiểm tra dữ liệu
for i, (inputs, labels) in enumerate(dataloader):
    print(f"Batch {i+1}:")
    print("Inputs:", inputs)
    print("Labels:", labels)
    if i == 2:  # In ra 3 batch đầu tiên
        break

# Tạo dữ liệu
dataset = IrisTorch(X, y)

# Bước 4: Chia tập dữ liệu thành tập huấn luyện và tập kiểm tra bằng cách chia ngẫu nhiên 70,30.
train_size = int(0.7 * len(dataset))                  # 70%
test_size = len(dataset) - train_size                 #30%
train_dataset, test_dataset = random_split(dataset, [train_size, test_size])

# Tạo DataLoader cho tập huấn luyện và tập kiểm tra với batch_size = 64
batch_size = 64
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# Kiểm tra dữ liệu
for i, (inputs, labels) in enumerate(train_loader):
    print(f"Train Batch {i+1}:")
    print("Inputs:", inputs)
    print("Labels:", labels)
    if i == 2:  # In ra 3 batch đầu tiên
        break

for i, (inputs, labels) in enumerate(test_loader):
    print(f"Test Batch {i+1}:")
    print("Inputs:", inputs)
    print("Labels:", labels)
    if i == 2:  # In ra 3 batch đầu tiên
        break

# Tạo dữ liệu
dataset = IrisTorch(X, y)

# Chia tập dữ liệu thành tập huấn luyện và tập kiểm tra
train_size = int(0.7 * len(dataset))  # 70%
test_size = len(dataset) - train_size  # 30%
train_dataset, test_dataset = random_split(dataset, [train_size, test_size])

# Tạo DataLoader cho tập huấn luyện và tập kiểm tra với batch_size = 64
batch_size = 64
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# Bước 5: Định nghĩa criterion và optimizer
n_features = X.shape[1]
model = LogisticRegressTorch(n_features)

criterion = nn.BCELoss()  # Hàm mất mát Binary Cross-Entropy Loss
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  # Trình tối ưu hóa SGD với learning rate = 0.01

# Kiểm tra dữ liệu
for i, (inputs, labels) in enumerate(train_loader):
    print(f"Train Batch {i+1}:")
    print("Inputs:", inputs)
    print("Labels:", labels)
    if i == 2:  # In ra 3 batch đầu tiên
        break

for i, (inputs, labels) in enumerate(test_loader):
    print(f"Test Batch {i+1}:")
    print("Inputs:", inputs)
    print("Labels:", labels)
    if i == 2:  # In ra 3 batch đầu tiên
        break

# Tạo dữ liệu
dataset = IrisTorch(X, y)

# Chia tập dữ liệu thành tập huấn luyện và tập kiểm tra
train_size = int(0.7 * len(dataset))  # 70%
test_size = len(dataset) - train_size  # 30%
train_dataset, test_dataset = random_split(dataset, [train_size, test_size])

# Tạo DataLoader cho tập huấn luyện và tập kiểm tra với batch_size = 64
batch_size = 64
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# Bước 4: Định nghĩa criterion và optimizer
n_features = X.shape[1]
model = LogisticRegressTorch(n_features)

criterion = nn.BCELoss()  # Hàm mất mát Binary Cross-Entropy Loss
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  # Trình tối ưu hóa SGD với learning rate = 0.01
# Huấn luyện mô hình
n_epochs = 200
train_losses = []
test_losses = []
test_accuracies = []

for epoch in range(n_epochs):
    model.train()
    train_loss = 0.0
    for inputs, targets in train_loader:
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * inputs.size(0)

    train_loss /= len(train_loader.dataset)
    train_losses.append(train_loss)

    # Đánh giá trên tập kiểm tra
    model.eval()
    test_loss = 0.0
    correct = 0
    total = 0
    with torch.no_grad():
        for inputs, targets in test_loader:
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            test_loss += loss.item() * inputs.size(0)

            predicted = (outputs >= 0.5).float()
            total += targets.size(0)
            correct += (predicted == targets).sum().item()

    test_loss /= len(test_loader.dataset)
    test_losses.append(test_loss)

    accuracy = correct / total
    test_accuracies.append(accuracy)

    print(f'Epoch {epoch+1}/{n_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}')

# Vẽ biểu đồ loss và accuracy
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Train Loss')
plt.plot(test_losses, label='Test Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Loss over Epochs')

plt.subplot(1, 2, 2)
plt.plot(test_accuracies, label='Test Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Accuracy over Epochs')

plt.show()

"""#Kết quả:

![image.png](attachment:image.png)
"""